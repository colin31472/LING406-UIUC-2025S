{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Naive Bayes (Validation) ===\n",
      "Accuracy: 0.6923\n",
      "Precision: 0.2474\n",
      "Recall: 0.0903\n",
      "F1-score: 0.1104\n",
      "\n",
      "=== Decision Tree (Validation) ===\n",
      "Accuracy: 0.4570\n",
      "Precision: 0.1653\n",
      "Recall: 0.0690\n",
      "F1-score: 0.0784\n",
      "\n",
      "=== Naive Bayes (Test) ===\n",
      "Accuracy: 0.6368\n",
      "Precision: 0.1960\n",
      "Recall: 0.0708\n",
      "F1-score: 0.0858\n",
      "\n",
      "=== Decision Tree (Test) ===\n",
      "Accuracy: 0.4529\n",
      "Precision: 0.1169\n",
      "Recall: 0.0511\n",
      "F1-score: 0.0569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# baseline.ipynb -Youngjun Yu\n",
    "# ========================================\n",
    "\n",
    "\"\"\"\n",
    "Overall steps:\n",
    "    1) Parse the training and validation sets.\n",
    "    2) Build context-window features for each token.\n",
    "    3) Train two classifiers.\n",
    "    4) Evaluate classifiers on the validation and test set.\n",
    "\"\"\"\n",
    "\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# 1. Load and Parse data\n",
    "\n",
    "def parse(file_path):\n",
    "    \"\"\"\n",
    "    Parses an XCES XML file (gzipped) and extracts sentences.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the .xml.gz file (relative path).\n",
    "        \n",
    "    Returns:\n",
    "        list of list of (str, str): A list of sentences; \n",
    "                                    each sentence is a list of (orth, ctag) tuples.\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "        tree = ET.parse(f)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        for chunk in root.findall('.//chunk'):\n",
    "            sentence_tokens = []\n",
    "            for tok in chunk.findall('tok'):\n",
    "                orth_elem = tok.find('orth')\n",
    "                lex_elem = tok.find('lex')\n",
    "                \n",
    "                if orth_elem is not None and lex_elem is not None:\n",
    "                    ctag_elem = lex_elem.find('ctag')\n",
    "                    if ctag_elem is not None:\n",
    "                        orth = orth_elem.text.strip()\n",
    "                        pos_tag = ctag_elem.text.strip()\n",
    "                        sentence_tokens.append((orth, pos_tag))\n",
    "            if sentence_tokens:\n",
    "                sentences.append(sentence_tokens)\n",
    "    return sentences\n",
    "\n",
    "train_sentences = parse(\"../Data/train.xml.gz\")\n",
    "validate_sentences = parse(\"../Data/validate.xml.gz\")\n",
    "test_sentences = parse(\"../Data/test-1-1.xml.gz\")\n",
    "\n",
    "\n",
    "# 2. Create a function to build context features\n",
    "\n",
    "def build_features(sentences, window=1):\n",
    "    \"\"\"\n",
    "    Build a feature representation for each token in each sentence \n",
    "    using a simple bag-of-words context window.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for sentence in sentences:\n",
    "        tokens = [tok for tok, _ in sentence]\n",
    "        pos_tags = [pt for _, pt in sentence]\n",
    "        \n",
    "        for i in range(len(tokens)):\n",
    "            target_token = tokens[i]\n",
    "            target_pos = pos_tags[i]\n",
    "            \n",
    "            # Build features for the target token\n",
    "            features = {}\n",
    "            \n",
    "            # 1) Current token\n",
    "            features[\"token\"] = target_token.lower()\n",
    "            \n",
    "            # 2) Context to the left\n",
    "            for w in range(1, window+1):\n",
    "                left_i = i - w\n",
    "                if left_i >= 0:\n",
    "                    features[f\"left_{w}\"] = tokens[left_i].lower()\n",
    "                else:\n",
    "                    features[f\"left_{w}\"] = \"<PAD>\"\n",
    "            \n",
    "            # 3) Context to the right\n",
    "            for w in range(1, window+1):\n",
    "                right_i = i + w\n",
    "                if right_i < len(tokens):\n",
    "                    features[f\"right_{w}\"] = tokens[right_i].lower()\n",
    "                else:\n",
    "                    features[f\"right_{w}\"] = \"<PAD>\"\n",
    "            \n",
    "            X.append(features)\n",
    "            y.append(target_pos)\n",
    "    return X, y\n",
    "\n",
    "X_train_dict, y_train = build_features(train_sentences, window=1)\n",
    "X_validate_dict, y_validate = build_features(validate_sentences, window=1)\n",
    "X_test_dict, y_test = build_features(test_sentences, window=1)\n",
    "\n",
    "X_full_dict = X_train_dict + X_validate_dict\n",
    "y_full = y_train + y_validate\n",
    "\n",
    "\n",
    "# 3. Vectorize features\n",
    "vec = DictVectorizer(sparse=True)\n",
    "X_full = vec.fit_transform(X_full_dict)\n",
    "X_validate = vec.transform(X_validate_dict)\n",
    "X_test = vec.transform(X_test_dict)\n",
    "\n",
    "\n",
    "# 4. Train two classifiers and evaluate\n",
    "\n",
    "# Classifier 1: Naive Bayes\n",
    "NB = MultinomialNB()\n",
    "NB.fit(X_full, y_full)\n",
    "y_pred_NB_test = NB.predict(X_test)\n",
    "y_pred_NB_val = NB.predict(X_validate)\n",
    "\n",
    "# Classifier 2: Decision Tree\n",
    "DT = DecisionTreeClassifier(\n",
    "    random_state=0,\n",
    "    max_depth=100\n",
    ")\n",
    "DT.fit(X_full, y_full)\n",
    "y_pred_DT_test = DT.predict(X_test)\n",
    "y_pred_DT_val = DT.predict(X_validate)\n",
    "\n",
    "\n",
    "# 5. Evaluate and print metrics\n",
    "\n",
    "def evaluate(y_true, y_pred, model_name):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='macro', zero_division=0\n",
    "    )\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"=== {model_name} ===\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(\"\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "evaluate(y_validate, y_pred_NB_val, model_name=\"Naive Bayes (Validation)\")\n",
    "evaluate(y_validate, y_pred_DT_val, model_name=\"Decision Tree (Validation)\")\n",
    "\n",
    "# Evaluate on test set\n",
    "evaluate(y_test, y_pred_NB_test, model_name=\"Naive Bayes (Test)\")\n",
    "evaluate(y_test, y_pred_DT_test, model_name=\"Decision Tree (Test)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
