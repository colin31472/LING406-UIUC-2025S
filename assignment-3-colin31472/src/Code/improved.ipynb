{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Naive Bayes (Validation) ===\n",
      "Accuracy: 0.5330\n",
      "Precision: 0.0865\n",
      "Recall: 0.0304\n",
      "F1-score: 0.0329\n",
      "\n",
      "=== Decision Tree (Validation) ===\n",
      "Accuracy: 0.4762\n",
      "Precision: 0.2502\n",
      "Recall: 0.0937\n",
      "F1-score: 0.1093\n",
      "\n",
      "=== Naive Bayes (Test) ===\n",
      "Accuracy: 0.4903\n",
      "Precision: 0.0733\n",
      "Recall: 0.0249\n",
      "F1-score: 0.0264\n",
      "\n",
      "=== Decision Tree (Test) ===\n",
      "Accuracy: 0.4645\n",
      "Precision: 0.1439\n",
      "Recall: 0.0626\n",
      "F1-score: 0.0707\n",
      "\n",
      "=== Leave-One-Feature-Out Results (Difference in performance) ===\n",
      "                         Feature Group Removed  NB_Accuracy_Diff  NB_F1_Diff  DT_Accuracy_Diff  DT_F1_Diff\n",
      "                                       [token]          0.148015    0.018288          0.262512    0.099593\n",
      "                                       [shape]          0.041189    0.003862          0.184374    0.031922\n",
      "[left_1, left_1_shape, right_1, right_1_shape]         -0.004789   -0.001370          0.054460    0.063413\n",
      "[left_2, left_2_shape, right_2, right_2_shape]         -0.070601   -0.016463          0.016558    0.026570\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# improved.ipynb- Youngjun Yu\n",
    "# ========================================\n",
    "\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# 1. Load and Parse data\n",
    "\n",
    "def parse(file_path):\n",
    "    \"\"\"\n",
    "    Parses an XCES XML file (gzipped) and extracts sentences.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the .xml.gz file (relative path).\n",
    "        \n",
    "    Returns:\n",
    "        list of list of (str, str): A list of sentences; \n",
    "                                    each sentence is a list of (orth, ctag) tuples.\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "        tree = ET.parse(f)\n",
    "        root = tree.getroot()\n",
    "        for chunk in root.findall('.//chunk'):\n",
    "            sentence_tokens = []\n",
    "            for tok in chunk.findall('tok'):\n",
    "                orth_elem = tok.find('orth')\n",
    "                lex_elem = tok.find('lex')\n",
    "                if orth_elem is not None and lex_elem is not None:\n",
    "                    ctag_elem = lex_elem.find('ctag')\n",
    "                    if ctag_elem is not None:\n",
    "                        orth = orth_elem.text.strip()\n",
    "                        pos_tag = ctag_elem.text.strip()\n",
    "                        sentence_tokens.append((orth, pos_tag))\n",
    "            if sentence_tokens:\n",
    "                sentences.append(sentence_tokens)\n",
    "    return sentences\n",
    "\n",
    "train_sentences = parse(\"../Data/train.xml.gz\")\n",
    "validate_sentences = parse(\"../Data/validate.xml.gz\")\n",
    "test_sentences = parse(\"../Data/test-1-1.xml.gz\")\n",
    "\n",
    "\n",
    "# 2. Build improved features\n",
    "\n",
    "def token_shape(token):\n",
    "    \"\"\"\n",
    "    Simple function to capture shape features of a token.\n",
    "    \"\"\"\n",
    "    shape_str = []\n",
    "    for char in token:\n",
    "        if char.isdigit():\n",
    "            shape_str.append('d')\n",
    "        elif char.isalpha():\n",
    "            if char.isupper():\n",
    "                shape_str.append('X')\n",
    "            else:\n",
    "                shape_str.append('x')\n",
    "        else:\n",
    "            shape_str.append(char)\n",
    "    return \"\".join(shape_str)\n",
    "\n",
    "\n",
    "def build_improved_features(sentences, window=2):\n",
    "    \"\"\"\n",
    "    Build a feature representation for each token using:\n",
    "      - bigger context window\n",
    "      - token shape\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for sent in sentences:\n",
    "        tokens = [t for t, _ in sent]\n",
    "        pos_tags = [p for _, p in sent]\n",
    "\n",
    "        for i in range(len(tokens)):\n",
    "            target_token = tokens[i]\n",
    "            target_pos = pos_tags[i]\n",
    "\n",
    "            features = {}\n",
    "            # Current token (lowercased)\n",
    "            features[\"token\"] = target_token.lower()\n",
    "            # Token shape\n",
    "            features[\"shape\"] = token_shape(target_token)\n",
    "\n",
    "            # Bigger context window\n",
    "            for w in range(1, window + 1):\n",
    "                left_i = i - w\n",
    "                right_i = i + w\n",
    "                # left token\n",
    "                if left_i >= 0:\n",
    "                    features[f\"left_{w}\"] = tokens[left_i].lower()\n",
    "                    features[f\"left_{w}_shape\"] = token_shape(tokens[left_i])\n",
    "                else:\n",
    "                    features[f\"left_{w}\"] = \"<PAD>\"\n",
    "                    features[f\"left_{w}_shape\"] = \"<PAD>\"\n",
    "\n",
    "                # right token\n",
    "                if right_i < len(tokens):\n",
    "                    features[f\"right_{w}\"] = tokens[right_i].lower()\n",
    "                    features[f\"right_{w}_shape\"] = token_shape(tokens[right_i])\n",
    "                else:\n",
    "                    features[f\"right_{w}\"] = \"<PAD>\"\n",
    "                    features[f\"right_{w}_shape\"] = \"<PAD>\"\n",
    "\n",
    "            X.append(features)\n",
    "            y.append(target_pos)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_train_dict, y_train = build_improved_features(train_sentences, window=2)\n",
    "X_validate_dict, y_validate = build_improved_features(validate_sentences, window=2)\n",
    "X_test_dict, y_test = build_improved_features(test_sentences, window=2)\n",
    "\n",
    "X_full_dict = X_train_dict + X_validate_dict\n",
    "y_full = y_train + y_validate\n",
    "\n",
    "\n",
    "# 3. Vectorize features\n",
    "\n",
    "vec = DictVectorizer(sparse=True)\n",
    "X_full = vec.fit_transform(X_full_dict)\n",
    "X_validate = vec.transform(X_validate_dict)\n",
    "X_test = vec.transform(X_test_dict)\n",
    "\n",
    "\n",
    "# 4. Train classifiers (Naive Bayes, Decision Tree) on improved features\n",
    "\n",
    "NB = MultinomialNB()\n",
    "NB.fit(X_full, y_full)\n",
    "y_pred_nb_test = NB.predict(X_test)\n",
    "y_pred_nb_val = NB.predict(X_validate)\n",
    "\n",
    "DT = DecisionTreeClassifier(\n",
    "    random_state=0,\n",
    "    max_depth=100\n",
    ")\n",
    "DT.fit(X_full, y_full)\n",
    "y_pred_dt_test = DT.predict(X_test)\n",
    "y_pred_dt_val = DT.predict(X_validate)\n",
    "\n",
    "\n",
    "# 5. Evaluate\n",
    "\n",
    "def evaluate(y_true, y_pred, model_name=\"\"):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='macro', zero_division=0\n",
    "    )\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"=== {model_name} ===\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(\"\")\n",
    "    \n",
    "evaluate(y_validate, y_pred_nb_val, model_name=\"Naive Bayes (Validation)\")\n",
    "evaluate(y_validate, y_pred_dt_val, model_name=\"Decision Tree (Validation)\")\n",
    "\n",
    "evaluate(y_test, y_pred_nb_test, model_name=\"Naive Bayes (Test)\")\n",
    "evaluate(y_test, y_pred_dt_test, model_name=\"Decision Tree (Test)\")\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# Feature Engineering (Leave-One-Feature-Out)\n",
    "###############################################################\n",
    "\n",
    "# Let's define the \"attributes\" as the presence of:\n",
    "#   - 'token'\n",
    "#   - 'shape'\n",
    "#   - 'left_X', 'left_X_shape', 'right_X', 'right_X_shape' for X in [1..window]\n",
    "\n",
    "def leave_one_out_experiment(X_dict, y, vec_fit, features_to_remove):\n",
    "    \"\"\"\n",
    "    Remove the specified features from each dictionary in X_dict,\n",
    "    then transform and evaluate using a chosen model.\n",
    "    \"\"\"\n",
    "    X_modified = []\n",
    "    for feat_dict in X_dict:\n",
    "        new_dict = {k: v for k, v in feat_dict.items() if k not in features_to_remove}\n",
    "        X_modified.append(new_dict)\n",
    "    \n",
    "    X_modified_transformed = vec_fit.transform(X_modified)\n",
    "    return X_modified_transformed\n",
    "\n",
    "# Base performance with all features\n",
    "base_nb_pred = NB.predict(X_validate)\n",
    "base_dt_pred = DT.predict(X_validate)\n",
    "\n",
    "base_nb_precision, base_nb_recall, base_nb_f1, _ = precision_recall_fscore_support(\n",
    "    y_validate, base_nb_pred, average='macro', zero_division=0\n",
    ")\n",
    "base_nb_acc = accuracy_score(y_validate, base_nb_pred)\n",
    "\n",
    "base_dt_precision, base_dt_recall, base_dt_f1, _ = precision_recall_fscore_support(\n",
    "    y_validate, base_dt_pred, average='macro', zero_division=0\n",
    ")\n",
    "base_dt_acc = accuracy_score(y_validate, base_dt_pred)\n",
    "\n",
    "feature_groups = [\n",
    "    [\"token\"],\n",
    "    [\"shape\"],\n",
    "    [\"left_1\", \"left_1_shape\", \"right_1\", \"right_1_shape\"],\n",
    "    [\"left_2\", \"left_2_shape\", \"right_2\", \"right_2_shape\"],\n",
    "]\n",
    "\n",
    "results = []\n",
    "for group in feature_groups:\n",
    "    # Remove one group from X_validate_dict\n",
    "    X_val_no_group = leave_one_out_experiment(X_validate_dict, y_validate, vec, group)\n",
    "    \n",
    "    # Evaluate NB\n",
    "    y_pred_nb_no_group = NB.predict(X_val_no_group)\n",
    "    pr_nb, re_nb, f1_nb, _ = precision_recall_fscore_support(\n",
    "        y_validate, y_pred_nb_no_group, average='macro', zero_division=0\n",
    "    )\n",
    "    acc_nb = accuracy_score(y_validate, y_pred_nb_no_group)\n",
    "    \n",
    "    # Evaluate DT\n",
    "    y_pred_dt_no_group = DT.predict(X_val_no_group)\n",
    "    pr_dt, re_dt, f1_dt, _ = precision_recall_fscore_support(\n",
    "        y_validate, y_pred_dt_no_group, average='macro', zero_division=0\n",
    "    )\n",
    "    acc_dt = accuracy_score(y_validate, y_pred_dt_no_group)\n",
    "    \n",
    "    # Compute difference from the base\n",
    "    # (performance with all features) - (performance with one group removed)\n",
    "    nb_f1_diff = base_nb_f1 - f1_nb\n",
    "    dt_f1_diff = base_dt_f1 - f1_dt\n",
    "    \n",
    "    results.append({\n",
    "        \"Feature Group Removed\": group,\n",
    "        \"NB_Accuracy_Diff\": base_nb_acc - acc_nb,\n",
    "        \"NB_F1_Diff\": nb_f1_diff,\n",
    "        \"DT_Accuracy_Diff\": base_dt_acc - acc_dt,\n",
    "        \"DT_F1_Diff\": dt_f1_diff\n",
    "    })\n",
    "\n",
    "# Print results in a table\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"=== Leave-One-Feature-Out Results (Difference in performance) ===\")\n",
    "print(df_results.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
